{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference result: [array([[0.00013267]], dtype=float32), array([[5.5803293e-06]], dtype=float32), array([[4.9392547e-06]], dtype=float32), array([[0.98881394]], dtype=float32), array([[0.00297986]], dtype=float32), array([[0.95340186]], dtype=float32), array([[4.0049257e-05]], dtype=float32), array([[0.00351212]], dtype=float32), array([[0.00054073]], dtype=float32), array([[1.1434335e-05]], dtype=float32), array([[0.99991477]], dtype=float32), array([[0.03932006]], dtype=float32), array([[0.19710074]], dtype=float32), array([[0.0002506]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "# Load TFLite model and allocate tensors\n",
    "interpreter = tflite.Interpreter(model_path='Training/my_model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input details\n",
    "input_details = interpreter.get_input_details()\n",
    "\n",
    "# Load and preprocess image\n",
    "image_path = '/home/ali/projects/face-describer/download.jpeg'\n",
    "image = Image.open(image_path)\n",
    "image = image.resize((input_details[0]['shape'][1], input_details[0]['shape'][2]))\n",
    "image_array = np.asarray(image, dtype=np.float32) / 255.0\n",
    "image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
    "\n",
    "# Resize input tensor if necessary\n",
    "interpreter.resize_tensor_input(input_details[0]['index'], (1, input_details[0]['shape'][1], input_details[0]['shape'][2], 3))\n",
    "\n",
    "# Set input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], image_array)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "sorted_output_details = sorted(output_details, key=lambda x: x['index'])\n",
    "\n",
    "# Print the sorted output data and details\n",
    "output_data = [interpreter.get_tensor(sorted_output_details[i]['index']) for i in range(len(output_details))]\n",
    "print(\"Inference result:\", output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "prediction_scores = [arr[0][0] for arr in output_data]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.00013266593,\n 5.5803293e-06,\n 4.9392547e-06,\n 0.98881394,\n 0.0029798595,\n 0.95340186,\n 4.0049257e-05,\n 0.0035121187,\n 0.0005407275,\n 1.1434335e-05,\n 0.99991477,\n 0.039320055,\n 0.19710074,\n 0.00025060476]"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/ali/projects/face-describer'"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "attributes = [\"5_o_Clock_Shadow\", \"Bald\", \"Black_Hair\", \"Blond_Hair\", \"Brown_Hair\",\n",
    "              \"Eyeglasses\", \"Goatee\", \"Gray_Hair\", \"Male\", \"Mustache\", \"Smiling\", \"No_Beard\",\n",
    "              \"Wearing_Earrings\", \"Wearing_Hat\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_o_Clock_Shadow          False 0.00013266593\n",
      "Bald          False 5.5803293e-06\n",
      "Black_Hair          False 4.9392547e-06\n",
      "Blond_Hair          True 0.98881394\n",
      "Brown_Hair          False 0.0029798595\n",
      "Eyeglasses          True 0.95340186\n",
      "Goatee          False 4.0049257e-05\n",
      "Gray_Hair          False 0.0035121187\n",
      "Male          False 0.0005407275\n",
      "Mustache          False 1.1434335e-05\n",
      "Smiling          True 0.99991477\n",
      "No_Beard          False 0.039320055\n",
      "Wearing_Earrings          False 0.19710074\n",
      "Wearing_Hat          False 0.00025060476\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(output_data)):\n",
    "    print (attributes[i],\"        \" ,  output_data[i][0][0] > 0.5, output_data[i][0][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
